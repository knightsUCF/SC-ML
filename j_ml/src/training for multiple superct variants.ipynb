{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"training for multiple superct variants.ipynb","provenance":[],"machine_shape":"hm","mount_file_id":"1EbJPqWKsJ3zzpMwEUpMOpQl9FWVl85K8","authorship_tag":"ABX9TyM65777lGx/AwysYQvsrfbd"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"PahBLXkd2zZf"},"source":["import numpy as np\n","import pandas as pd\n","\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.layers import Dropout\n","from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n","from tensorflow.keras import utils\n","\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import cross_val_score\n","from sklearn.model_selection import KFold\n","\n","import os\n","import math"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rszyMaQcmqqi"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gCTH9nrC3_5W"},"source":["# remove one dropout layer\n","def create_superct_model(n_features, n_targets):\n","    model = Sequential()\n","    model.add(Dense(200, input_dim = n_features, activation = 'relu'))\n","    model.add(Dropout(0.4))\n","    model.add(Dense(100, activation = 'relu'))\n","    model.add(Dropout(0.4))\n","    model.add(Dense(n_targets, activation = 'relu'))\n","    model.compile(optimizer='SGD', loss='categorical_crossentropy', metrics=['accuracy'])\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"i85j-AyE5iAS"},"source":["def train_and_save(file_dir, output_dir):\n","    if not os.path.exists(output_dir):\n","        os.mkdir(output_dir)\n","\n","    print('start to process %s'%file_dir)\n","\n","    d_df = pd.read_csv(file_dir)\n","    X = d_df.iloc[:,1:-2]\n","    y = d_df['target_id']\n","    enc = LabelEncoder()\n","    enc.fit(y)\n","    encoded_Y = enc.transform(y)\n","    dummy_y = utils.to_categorical(encoded_Y)\n","\n","    batch_size = 128\n","    # round up the epches\n","    num_epoches = math.ceil(X.shape[0]/batch_size)\n","\n","    # training the model\n","    print('start training')\n","    estimator = KerasClassifier(build_fn=create_superct_model,n_features=X.shape[1], n_targets=dummy_y.shape[1], epochs=num_epoches, batch_size=batch_size, verbose=0)\n","    kfold = KFold(n_splits=10, shuffle=True)\n","    results = cross_val_score(estimator, X, dummy_y, cv=kfold, verbose=1)\n","\n","    # save files\n","    file_name = os.path.basename(file_dir)\n","    history_name = file_name.replace('.csv', '.txt')\n","    history_name = os.path.join(output_dir, history_name)\n","\n","    # content to be saved\n","    results_mean = str(results.mean()*100)+'%'\n","    results_std = str(results.std()*100)+'%'\n","    results_str = 'mean accuracy: '+results_mean+'\\t'+'std: '+results_std\n","    print('start writing files')\n","    with open(history_name, 'w') as f:\n","        f.write(file_name)\n","        f.write('\\n')\n","        f.write('the number of observations: %d'%X.shape[0])\n","        f.write('\\n')\n","        f.write('the number of features: %d'%X.shape[1])\n","        f.write('\\n')\n","        f.write('the number of targets: %d'%dummy_y.shape[1])\n","        f.write('\\n')\n","        f.write(results_str)\n","    print('finished processing %s'%file_name)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6V-6-Nc-Oz9b"},"source":["processed_file_list = []\n","for root, dirs, files in os.walk(\"/content/drive/MyDrive/Colab Notebooks/superct_v1\", topdown=False):\n","     for name in files:\n","       processed_file_list.append(name.replace('.txt','.csv'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4tksw6M65le4","outputId":"2b99cc41-dfa3-45da-a57c-943dfe419ecb"},"source":[" # processed_dge folder contains all new defined datasets\n"," # get all shapes from processed_dge files\n","for root, dirs, files in os.walk(\"/content/drive/MyDrive/Colab Notebooks/pre_processed_datasets\", topdown=False):\n","  for name in files:\n","    if name not in processed_file_list:\n","      file_dir = os.path.join(root, name)\n","      train_and_save(file_dir, '/content/drive/MyDrive/Colab Notebooks/superct_v1')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["start to process /content/drive/MyDrive/Colab Notebooks/pre_processed_datasets/TrophoblastStemCells_1.csv\n","start training\n"],"name":"stdout"},{"output_type":"stream","text":["[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"4e_-OTam5_sq"},"source":["# remove all dropout layers\n","def create_superct_model(n_features, n_targets):\n","    model = Sequential()\n","    model.add(Dense(200, input_dim = n_features, activation = 'relu'))\n","    model.add(Dense(100, activation = 'relu'))\n","    model.add(Dense(n_targets, activation = 'relu'))\n","    model.compile(optimizer='SGD', loss='categorical_crossentropy', metrics=['accuracy'])\n","    return model\n","\n","def train_and_save(file_dir, output_dir):\n","    if not os.path.exists(output_dir):\n","        os.mkdir(output_dir)\n","\n","    print('start to process %s'%file_dir)\n","\n","    d_df = pd.read_csv(file_dir)\n","    X = d_df.iloc[:,1:-2]\n","    y = d_df['target_id']\n","    enc = LabelEncoder()\n","    enc.fit(y)\n","    encoded_Y = enc.transform(y)\n","    dummy_y = utils.to_categorical(encoded_Y)\n","\n","    batch_size = 128\n","    # round up the epches\n","    num_epoches = math.ceil(X.shape[0]/batch_size)\n","\n","    # training the model\n","    print('start training')\n","    estimator = KerasClassifier(build_fn=create_superct_model,n_features=X.shape[1], n_targets=dummy_y.shape[1], epochs=num_epoches, batch_size=batch_size, verbose=0)\n","    kfold = KFold(n_splits=10, shuffle=True)\n","    results = cross_val_score(estimator, X, dummy_y, cv=kfold, verbose=1)\n","\n","    # save files\n","    file_name = os.path.basename(file_dir)\n","    history_name = file_name.replace('.csv', '.txt')\n","    history_name = os.path.join(output_dir, history_name)\n","\n","    # content to be saved\n","    results_mean = str(results.mean()*100)+'%'\n","    results_std = str(results.std()*100)+'%'\n","    results_str = 'mean accuracy: '+results_mean+'\\t'+'std: '+results_std\n","    print('start writing files')\n","    with open(history_name, 'w') as f:\n","        f.write(file_name)\n","        f.write('\\n')\n","        f.write('the number of observations: %d'%X.shape[0])\n","        f.write('\\n')\n","        f.write('the number of features: %d'%X.shape[1])\n","        f.write('\\n')\n","        f.write('the number of targets: %d'%dummy_y.shape[1])\n","        f.write('\\n')\n","        f.write(results_str)\n","    print('finished processing %s'%file_name)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hqBpSpzrhBZO"},"source":["processed_file_list = []\n","for root, dirs, files in os.walk(\"/content/drive/MyDrive/Colab Notebooks/superct_v2\", topdown=False):\n","     for name in files:\n","       processed_file_list.append(name.replace('.txt','.csv'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KeNjtozh6ob5"},"source":[" # processed_dge folder contains all new defined datasets\n"," # get all shapes from processed_dge files\n","for root, dirs, files in os.walk(\"/content/drive/MyDrive/Colab Notebooks/pre_processed_datasets\", topdown=False):\n","  for name in files:\n","    if name not in processed_file_list:\n","      file_dir = os.path.join(root, name)\n","      train_and_save(file_dir, '/content/drive/MyDrive/Colab Notebooks/superct_v2')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YFkG153j6wIH"},"source":[""],"execution_count":null,"outputs":[]}]}